{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LULC Base Create code  \n",
    "Creates the base LST grid for the LULC information to be added to  \n",
    "Change the CITY_COUNTRY variable and then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual entries\n",
    "CITY_COUNTRY = \"BIJAPUR_INDIA\"\n",
    "\n",
    "#aqua and terra grid same, doesn't matter which one you use\n",
    "#SATELLITE = 'MOD11A2' #TERRA\n",
    "SATELLITE = 'MYD11A2' #AQUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import earthpy as et\n",
    "import pickle\n",
    "#for the reprojecting\n",
    "import pyproj\n",
    "from pyproj import CRS, Proj\n",
    "from pyproj import Transformer\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from pyhdf.SD import SD, SDC\n",
    "import datetime as dt\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import re\n",
    "import fnmatch  #for finding other file when city+rural isn't all in the main one (bulawayo)\n",
    "\n",
    "\n",
    "#load in csv of city lons and lats\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT'))\n",
    "CITY_COUNTRY_lat_lon = pd.read_excel('CITY_COUNTRY_lat_lon.xlsx', index_col=None)\n",
    "#CITY_COUNTRY_lat_lon = pd.read_excel('CITY_COUNTRY_lat_lon2.xlsx', index_col=None)\n",
    "\n",
    "#set the city latitude and longitudes and city name\n",
    "City_Lat = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['Lat'].values[0]\n",
    "City_Lon = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['Lon'].values[0]\n",
    "City_name = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon['CITY_COUNTRY'] == CITY_COUNTRY]['City'].values[0]\n",
    "\n",
    "#Area to look at will be the city centre +/- 0.3/0.4 degs depending on city size\n",
    "min_lat = City_Lat - 0.3\n",
    "max_lat = City_Lat + 0.3\n",
    "min_lon = City_Lon - 0.3\n",
    "max_lon = City_Lon + 0.3\n",
    "\n",
    "#define function to create coordinate grid\n",
    "def grid_create(file_name):\n",
    "    # Identify the data field- use the LST day but grid is same for all data\n",
    "    DATAFIELD_NAME = 'LST_Day_1km'\n",
    "\n",
    "    GRID_NAME = 'MODIS_Grid_8Day_1km_LST'\n",
    "\n",
    "    hdf = SD(file_name, SDC.READ)\n",
    "\n",
    "    # Read dataset.\n",
    "    data2D = hdf.select(DATAFIELD_NAME)\n",
    "    data = data2D[:,:].astype(np.float64)\n",
    "\n",
    "    # Read global attribute.\n",
    "    fattrs = hdf.attributes(full=1)\n",
    "    ga = fattrs[\"StructMetadata.0\"]\n",
    "    gridmeta = ga[0]\n",
    "\n",
    "    # Construct the grid.  Required information in global attribute called 'StructMetadata.0'\n",
    "    \n",
    "    ul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n",
    "                                      (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n",
    "                                  ,\n",
    "                                      (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n",
    "                                      \\)''', re.VERBOSE)\n",
    "    match = ul_regex.search(gridmeta)\n",
    "    x0 = np.float(match.group('upper_left_x')) \n",
    "    y0 = np.float(match.group('upper_left_y')) \n",
    "\n",
    "    lr_regex = re.compile(r'''LowerRightMtrs=\\(\n",
    "                                      (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n",
    "                                      ,\n",
    "                                      (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n",
    "                                      \\)''', re.VERBOSE)\n",
    "    match = lr_regex.search(gridmeta)\n",
    "    x1 = np.float(match.group('lower_right_x')) \n",
    "    y1 = np.float(match.group('lower_right_y')) \n",
    "    ny, nx = data.shape\n",
    "    xinc = (x1 - x0) / nx\n",
    "    yinc = (y1 - y0) / ny\n",
    "\n",
    "    x = np.linspace(x0, x0 + xinc*nx, nx)\n",
    "    y = np.linspace(y0, y0 + yinc*ny, ny)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "    #transform to coordinates\n",
    "    transformer = Transformer.from_crs(\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\", \"EPSG:4326\")\n",
    "    lat, lon = transformer.transform(xv, yv)\n",
    "\n",
    "    #create dataframe of the coordinates\n",
    "    Lon_list = lon.flatten()\n",
    "    Lat_list = lat.flatten()\n",
    "\n",
    "    df = pd.DataFrame(list(zip(Lat_list, Lon_list)), \n",
    "                   columns =['Latitude', 'Longitude']) \n",
    "\n",
    "    #Create dataframe of the required area\n",
    "    df_subset = df[(df.Latitude > min_lat) & (df.Latitude < max_lat) & (df.Longitude > min_lon) & (df.Longitude < max_lon)]\n",
    "\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read daylist (could have used night, doesn't matter), pickle files back in from image select code. \n",
    "#Then select random image\n",
    "\n",
    "##Set path to chosen satellite\n",
    "os.chdir(os.path.join('D:\\\\','MODIS_8_day_LST', CITY_COUNTRY, SATELLITE))\n",
    "#with open('Day_list.pkl', 'rb') as f:\n",
    "#    Day_list = pickle.load(f)\n",
    "\n",
    "    #select file, doesn't matter which they are all on same grid\n",
    "#file_name = Day_list[10]\n",
    "file_name = 'MYD11A2.A2021185.h25v07.006.2021194055129.hdf'\n",
    "\n",
    "LULC_base = grid_create(file_name)\n",
    "\n",
    "if CITY_COUNTRY == \"BULAWAYO_ZIMBABWE\":\n",
    "#add in other files for cities where the rural extent goes outside of the grid box\n",
    "    #Set path to chosen satellite\n",
    "    os.chdir(os.path.join('D:\\\\','MODIS_8_day_LST', CITY_COUNTRY, SATELLITE,'CITY_TOP'))\n",
    "    \n",
    "    #extract the julian date of the main filename\n",
    "    yeardoy = file_name.split('.')[1][1:] \n",
    "\n",
    "    #find the filename which contains this in the top of city files\n",
    "    for file in os.listdir('.'):\n",
    "        if fnmatch.fnmatch(file, '*{}*'.format(yeardoy)):\n",
    "            top_file_name = file    \n",
    "    \n",
    "    top_file_df = grid_create(top_file_name)\n",
    "\n",
    "    LULC_base = LULC_base.append(top_file_df).reset_index(drop = True)\n",
    "    \n",
    "#save to csv to be used as the base to grid the LULC data to\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT','LULC_bases'))\n",
    "LULC_base.to_csv(r'LULC_base_{}.csv'.format(CITY_COUNTRY), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work out the local epsg and add these to the list of cities\n",
    "#only need to do this once\n",
    "#save as csv\n",
    "\n",
    "def utm_zoner(lon, lat):\n",
    "    utm_lon = lon+180\n",
    "    utm_zone = int(np.ceil(utm_lon/6))\n",
    "    south_hem =''\n",
    "    if lat<0:\n",
    "        south_hem = ' +south'\n",
    "    proj_str = f'+proj=utm +zone={utm_zone}{south_hem}'\n",
    "    return proj_str\n",
    "\n",
    "local_epsg_list = []\n",
    "for i in range(len(CITY_COUNTRY_lat_lon)):\n",
    "    City_Lon = CITY_COUNTRY_lat_lon['Lon'].values[i]\n",
    "    City_Lat = CITY_COUNTRY_lat_lon['Lat'].values[i]\n",
    "    local_utm = CRS.from_proj4(utm_zoner(City_Lon, City_Lat))\n",
    "    local_epsg = local_utm.to_epsg()\n",
    "    local_epsg_list.append(local_epsg)\n",
    "\n",
    "CITY_COUNTRY_lat_lon['Local_epsg'] = local_epsg_list \n",
    "\n",
    "#set path to save into and save as csv\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT'))\n",
    "CITY_COUNTRY_lat_lon.to_csv(r'CITY_COUNTRY_lat_lon2.csv', index = False)\n",
    "\n",
    "#also save as excel so have epsg for later\n",
    "CITY_COUNTRY_lat_lon.to_excel(\"CITY_COUNTRY_lat_lon2.xlsx\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
