{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ff8be6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'EF'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_244\\106365026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LOG_AREA'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMonthly_Area\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m# add sqrt values of climate variables (evi range is -1 to 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sqrt_EF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sqrt_RH'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sqrt_TP'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_monthly_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\suhienv2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5900\u001b[0m         ):\n\u001b[0;32m   5901\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5904\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'EF'"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "### Code to run ridge regression model for one city only ###\n",
    "############################################################\n",
    "\n",
    "CITY_COUNTRY = 'BIKANER_INDIA'\n",
    "\n",
    "#Read in the packages to use\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import earthpy as et\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random                                                        #for test city selection\n",
    "\n",
    "#for displaying the cities on map\n",
    "#import cartopy\n",
    "#import cartopy.crs as ccrs\n",
    "#import matplotlib as mpl\n",
    "#from matplotlib.ticker import ScalarFormatter\n",
    "#import matplotlib.ticker as ticker                                   #for setting axes ticks to whole numbers\n",
    "\n",
    "#models\n",
    "#from sklearn.linear_model import LinearRegression \n",
    "import statsmodels.api as sm                                          #stats models to get linear reg p-values\n",
    "from statsmodels.tools.eval_measures import rmse                      #calc rmse from stats models\n",
    "import itertools                                                      #for calculating possible combinations of variables\n",
    "from sklearn.preprocessing import PolynomialFeatures                  #for polynomial regression\n",
    "from sklearn.pipeline import make_pipeline                            #pipeline to create polynomial regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#use grid search to find hyperparameters (pg 73 Geron) RFR\n",
    "from sklearn.model_selection import GridSearchCV                      #for cross validation\n",
    "from sklearn.feature_selection import RFE                             #for selecting features for the linear reg\n",
    "from sklearn.model_selection import cross_val_score                   #for cross validation\n",
    "from sklearn.model_selection import KFold                            \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler                      #for normalising the data\n",
    "from sklearn.metrics import r2_score                                  #metrics for assessing model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#for plotting\n",
    "from matplotlib import ticker \n",
    "from matplotlib.ticker import MaxNLocator                             #to keep whole numbers on the x-axis\n",
    "from matplotlib.lines import Line2D                                   #for manual legend creation\n",
    "\n",
    "import math\n",
    "#Read in the data\n",
    "#read in the city info table\n",
    "#os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT', 'CITY_ADD_2022_09'))\n",
    "#CITY_COUNTRY_lat_lon = pd.read_excel('CITY_COUNTRY_lat_lon.xlsx', index_col=None)\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT', 'MEAN_SUHI'))\n",
    "CITY_COUNTRY_lat_lon = pd.read_excel('CITY_COUNTRY_lat_lon_mean.xlsx', index_col=None)\n",
    "\n",
    "#read the table with all variables in as pickle\n",
    "os.chdir(os.path.join(et.io.HOME, 'Documents', 'Python_Scripts', 'PROJECT','UHI_Project_Pickle_Files','All_cities'))   \n",
    "with open('aqua_all_monthly_data_df2.pkl', 'rb') as f:\n",
    "    all_monthly_data_df = pickle.load(f)\n",
    "\n",
    "# filter out data for the required city\n",
    "\n",
    "CITY_COUNTRY_lat_lon = CITY_COUNTRY_lat_lon[CITY_COUNTRY_lat_lon.CITY_COUNTRY == CITY_COUNTRY].reset_index(drop = True)\n",
    "all_monthly_data_df = all_monthly_data_df[all_monthly_data_df.CITY_COUNTRY == CITY_COUNTRY].reset_index(drop = True)\n",
    "    \n",
    "# Additional variables\n",
    "# add evi difference variable\n",
    "#all_monthly_data_df['EVI_D'] = all_monthly_data_df['EVI_U'] - all_monthly_data_df['EVI_R'] \n",
    "\n",
    "all_monthly_data_df['LOG_AREA'] = np.log10(all_monthly_data_df.Monthly_Area.values.astype(float))\n",
    "# add sqrt values of climate variables (evi range is -1 to 1)\n",
    "all_monthly_data_df['sqrt_EF'] = np.sqrt(all_monthly_data_df.EF.values.astype(float))\n",
    "all_monthly_data_df['sqrt_RH'] = np.sqrt(all_monthly_data_df.RH.values.astype(float))\n",
    "all_monthly_data_df['sqrt_TP'] = np.sqrt(all_monthly_data_df.TP.values.astype(float))\n",
    "all_monthly_data_df['sqrt_T2M'] = np.sqrt(all_monthly_data_df.T2M.values.astype(float))\n",
    "all_monthly_data_df['sqrt_SSR'] = np.sqrt(all_monthly_data_df.SSR.values.astype(float))\n",
    "# add one to the sqrt (evi variables +1)\n",
    "#all_monthly_data_df['sqrt_EVI_R_p1'] = np.sqrt(all_monthly_data_df.EVI_R.values.astype(float)+1)\n",
    "#all_monthly_data_df['sqrt_EVI_U_p1'] = np.sqrt(all_monthly_data_df.EVI_U.values.astype(float)+1)\n",
    "\n",
    "#all_monthly_data_df['cube_EVI_D'] = pow(all_monthly_data_df.EVI_D.values.astype(float), 3)\n",
    "\n",
    "all_monthly_data_df['CROPLAND'] = all_monthly_data_df['CROPLAND_RAIN'] + all_monthly_data_df['CROPLAND_IRR']\n",
    "# elevation diff\n",
    "all_monthly_data_df['ELEVATION_D'] = all_monthly_data_df['ELEVATION_U'] - all_monthly_data_df['ELEVATION_R']\n",
    "    \n",
    "\n",
    "#define the overpass time \n",
    "overpass_time = '13:30'\n",
    "\n",
    "#define the predictor and target values for training and test data\n",
    "#what predictors to use?\n",
    "predictor_variables_all = ['EF', 'RH', 'TP','T2M','SSR','EVI_U','EVI_R','EVI_D',\n",
    "                           'ECC', 'LOG_AREA', 'sqrt_EF','sqrt_RH','sqrt_TP','sqrt_T2M',\n",
    "                           'sqrt_SSR','sqrt_EVI_R_p1','sqrt_EVI_U_p1','sqrt_EVI_D_p1','CROPLAND_RAIN',\n",
    "                           'CROPLAND_IRR','GRASSLAND','BARE','WATER','cube_EVI_D',\n",
    "                         'ELEVATION_D','ROUGHNESS_LENGTH_R']\n",
    "\n",
    "\n",
    "predictor_variables_2 = ['EF','SSR', 'ECC', 'LOG_AREA', \n",
    "                         'sqrt_EF','sqrt_SSR', #'sqrt_EVI_R_p1','sqrt_EVI_U_p1','cube_EVI_D','EVI_U','EVI_R','EVI_D',\n",
    "                         'ELEVATION_D','ROUGHNESS_LENGTH_R']\n",
    "\n",
    "\n",
    "#'GRASSLAND',\n",
    "predictor_variables = predictor_variables_2\n",
    "\n",
    "#target_variable = 'SUHI_PEAK_GSA'\n",
    "#target_variable = 'SUHI_PEAK_QUANTILE'\n",
    "target_variable = 'SUHI_MEAN'\n",
    "#target_variable = 'SUHI_FP'\n",
    "\n",
    "#clean the data - first remove columns which are not the target or predictor variables, then remove nans\n",
    "variables = predictor_variables.copy()\n",
    "variables.append(target_variable)\n",
    "variables.append('Overpass')\n",
    "variables.append('month')\n",
    "variables.append('year')\n",
    "all_monthly_data_df2 = all_monthly_data_df[variables]\n",
    "all_monthly_data_df2 = all_monthly_data_df2.dropna().reset_index(drop = True)\n",
    "\n",
    "all_monthly_data_df3 = all_monthly_data_df[['EF','SSR','EVI_U','EVI_R','EVI_D', 'ECC', 'LOG_AREA', 'sqrt_EF','sqrt_SSR',\n",
    "            'sqrt_EVI_R_p1','sqrt_EVI_U_p1', 'CROPLAND','WATER','BARE','GRASSLAND','ROUGHNESS_LENGTH_R','month','City',\n",
    "                                            'Overpass']].dropna().reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training and test datasets\n",
    "#create the datasets\n",
    "training_data = all_monthly_data_df2[((all_monthly_data_df['year'] < 2016) \n",
    "                                    & (all_monthly_data_df2['Overpass'] == overpass_time))].copy()\n",
    "test_data = all_monthly_data_df2[((all_monthly_data_df['year'] >= 2016)\n",
    "                                  & (all_monthly_data_df2['Overpass'] == overpass_time))].copy()\n",
    " \n",
    "print('Train_percent', 100* len(training_data)/len(all_monthly_data_df2[all_monthly_data_df2['Overpass'] == overpass_time]))\n",
    "print('Test_percent', 100* len(test_data)/len(all_monthly_data_df2[all_monthly_data_df2['Overpass'] == overpass_time]))\n",
    "print('Total Datapoints',len(all_monthly_data_df2[all_monthly_data_df2['Overpass'] == overpass_time]))\n",
    "\n",
    "#split the data into training and test\n",
    "X_train = training_data[predictor_variables]  #predictors\n",
    "y_train = training_data[target_variable]      #target\n",
    "\n",
    "X_test = test_data[predictor_variables]       #predictors\n",
    "y_test = test_data[target_variable]           #target\n",
    "\n",
    "# get polynomail terms and interactions\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = pd.DataFrame(poly.fit_transform(X_train), columns = poly.get_feature_names_out(X_train.columns))\n",
    "X_train_poly = X_train_poly.drop('1', axis=1)\n",
    "\n",
    "X_test_poly = pd.DataFrame(poly.fit_transform(X_test), columns = poly.get_feature_names_out(X_test.columns))\n",
    "X_test_poly = X_test_poly.drop('1', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638dafb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4045d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
